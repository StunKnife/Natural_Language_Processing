# Natural_Language_Processing

Natural Language Processing refere-se a um conjunto de técnicas para lidar com dados de texto usando o PySpark. Os dados de texto podem ser:

   * estruturados ou não estruturados
    
e temos que aplicar várias etapas para torná-los prontos para análise. O NLP já é um grande contribuidor para vários aplicativos. Atualmente, existem muitos aplicativos de NLP que são muito usados pelas empresas, como:
   1. chatbot
   2. reconhecimento de fala
   3. tradução de idiomas
   4. sistemas de recomendação
   5. detecção de spam 
   6. análise de sentimento
   
Ou seja, área de ciência se preocupa em oferecer uma série de etapas para processar dados de texto e aplicar um Algoritmo de Aprendizado de Máquina sobre eles.

# Etapas envolvidas no NLP

Do ponto de vista de Machine Learning, existem cinco etapas principais que devem ser seguidas para preparar os dados de texto para análise. 
    1. Reading the corpus
    2. Tokenization
    3. Cleaning /Stopword removal
    4. Stemming
    5. Converting into Numerical Form 
    
** Corpus **

Um corpus é conhecido como a coleção inteira de documentos de texto. Por exemplo, suponha que temos milhares de e-mails em uma coleção que precisamos processar e analisar para nosso uso. Esse grupo de e-mails é conhecido como corpus, pois contém todos os documentos de texto.

** Tokenizar **
O método de dividir uma determinada frase ou coleção de palavras de um documento de texto em palavras separadas/individuais é conhecido como tokenização. Ele remove os caracteres desnecessários, como pontuação. Por exemplo, se tivermos uma frase como: 
    1. Entrada: ** Ele gostou muito da cidade de Londres. Ele está lá por mais dois dias.**
    2. Tokens: ** Ele, realmente, gostou de, Londres, Cidade, Ele, está, lá, por, dois, mais, dias **
Terminamos com 13 fichas para a frase de entrada acima.


    
